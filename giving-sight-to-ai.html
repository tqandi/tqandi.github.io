<!DOCTYPE html>
<html lang="en">
<head>
    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-Z65QFE9R6Z"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-Z65QFE9R6Z');
</script>

    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>More Than a Thousand Words: AI for the Visually Impaired</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;700;900&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #1a103c;
            color: #e0e0e0;
        }
        .gradient-text {
            background: -webkit-linear-gradient(45deg, #f3ec78, #af4261);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }
        .hero-bg {
            /* * The background image is set here. A semi-transparent overlay is placed
             * on top of this in the HTML to ensure the text is readable.
             */
            background-image: url('https://images.unsplash.com/photo-1531746790731-6c087fecd65a?q=80&w=2148&auto=format&fit=crop');
            background-size: cover;
            background-position: center;
            background-repeat: no-repeat;
        }
        .card {
            background-color: rgba(42, 25, 80, 0.6);
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.1);
        }
        .stat-number {
            font-weight: 900;
            font-size: 5rem;
            line-height: 1;
            background: -webkit-linear-gradient(45deg, #8A2BE2, #FF69B4);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }
        .btn-reveal {
            transition: all 0.3s ease;
        }
        .caption-level {
            transition: all 0.5s ease-in-out;
            max-height: 0;
            overflow: hidden;
            opacity: 0;
        }
        .caption-level.active {
            max-height: 200px; /* Adjust as needed */
            opacity: 1;
            margin-top: 1rem;
        }
    </style>
</head>
<body class="antialiased">

    <!-- Hero Section -->
    <header class="hero-bg relative min-h-screen flex items-center justify-center text-center p-6">
        <div class="absolute inset-0 bg-black opacity-60"></div>
        <div class="relative z-10">
            <h1 class="text-4xl md:text-6xl font-black text-white leading-tight mb-4">More Than a Thousand Words</h1>
            <p class="text-xl md:text-2xl font-light text-gray-300 mb-6 max-w-3xl mx-auto">Teaching AI to See for the Visually Impaired</p>
            <div class="text-gray-400">
                <p>By Taraneh Ghandi</p>
                <p>Ferdowsi University of Mashhad</p>
            </div>
        </div>
    </header>

    <main class="py-16 md:py-24">
        <!-- The Problem Section -->
        <section class="container mx-auto px-6 mb-24">
            <div class="text-center mb-12">
                <h2 class="text-3xl md:text-4xl font-bold text-white">The Challenge</h2>
                <p class="text-lg text-gray-400 mt-2 max-w-2xl mx-auto">A picture is worth a thousand words, but only if you can see it.</p>
            </div>
            <div class="grid md:grid-cols-2 gap-8 items-center">
                <div class="text-center md:text-left">
                    <p class="stat-number">253M</p>
                    <p class="text-xl font-bold text-white mt-2">people worldwide live with visual impairments.</p>
                    <p class="text-gray-400 mt-4">For them, the digital world, built on images, can feel like a book with most of its pages torn out. Standard AI offers literal, unhelpful captions, missing the story and emotion that give an image meaning.</p>
                </div>
                <div class="grid grid-cols-1 gap-4">
                    <div class="card p-6 rounded-lg">
                        <p class="text-sm text-gray-400 mb-2">Standard AI sees:</p>
                        <p class="text-lg text-white font-semibold">"A group of people on a street."</p>
                    </div>
                    <div class="card p-6 rounded-lg">
                        <p class="text-sm text-pink-400 mb-2">What's really there:</p>
                        <p class="text-lg text-white font-semibold">A triumphant marathon finish line.</p>
                    </div>
                </div>
            </div>
        </section>

        <!-- The Solution Section -->
        <section class="container mx-auto px-6 mb-24">
            <div class="text-center mb-12">
                <h2 class="text-3xl md:text-4xl font-bold text-white">Our Innovation: A New Approach</h2>
                <p class="text-lg text-gray-400 mt-2 max-w-2xl mx-auto">We don't just need AI that labels images; we need AI that understands them.</p>
            </div>
            <div class="card p-8 rounded-xl">
                 <div class="grid md:grid-cols-2 gap-8 items-center">
                    <div>
                        <h3 class="text-2xl font-bold text-white mb-4">Building a Blueprint of the Scene</h3>
                        <p class="text-gray-300 mb-4">Before our system writes a single word, it creates a "scene graph"â€”a structured blueprint of everything in the image. It doesn't just see a "bird"; it identifies the bird, its attributes ("small," "blue"), and its relationship to other objects ("flying over the water").</p>
                        <p class="text-gray-300">By converting visual chaos into an organized map, we give the AI a deeper understanding. We fused this with powerful models like <span class="font-semibold text-cyan-400">CLIP</span> and <span class="font-semibold text-cyan-400">GPT-2</span> to construct descriptions from a foundation of understood facts.</p>
                    </div>
                    <div class="w-full">
                        <img src="https://i.imgur.com/k2gYfM7.png" alt="ClipCapGAT Architecture Diagram" class="rounded-lg bg-gray-800 p-2" onerror="this.onerror=null;this.src='https://placehold.co/600x350/2a1950/ffffff?text=Architecture+Diagram';">
                        <p class="text-xs text-center text-gray-500 mt-2">The ClipCapGAT architecture, combining scene graphs with CLIP and GPT-2.</p>
                    </div>
                </div>
            </div>
        </section>

        <!-- Controllable Captions Section -->
        <section class="container mx-auto px-6 mb-24">
            <div class="text-center mb-12">
                <h2 class="text-3xl md:text-4xl font-bold text-white">Captions on Demand</h2>
                <p class="text-lg text-gray-400 mt-2 max-w-2xl mx-auto">This deeper understanding unlocks our most important feature: hierarchical, controllable captions.</p>
            </div>
            <div class="grid md:grid-cols-2 gap-8 items-center">
                <div class="w-full h-64 md:h-96 rounded-xl bg-cover bg-center" style="background-image: url('https://images.unsplash.com/photo-1556911220-e15b29be8c8f?q=80&w=2070&auto=format&fit=crop')" onerror="this.onerror=null;this.style.backgroundImage='url(https://placehold.co/600x400/2a1950/ffffff?text=Kitchen+Scene)'">
                </div>
                <div>
                    <h3 class="text-2xl font-bold text-white mb-4">Putting the User in Control</h3>
                    <p class="text-gray-300 mb-6">Instead of one static description, the user can explore the image at their own pace. This simple shift empowers the user, giving them the agency to explore a visual world on their own terms.</p>
                    <div id="caption-controls">
                        <button class="btn-reveal bg-purple-600 hover:bg-purple-700 text-white font-bold py-2 px-4 rounded-lg" onclick="revealCaption(1)">Level 1: The Gist</button>
                        <button class="btn-reveal bg-pink-600 hover:bg-pink-700 text-white font-bold py-2 px-4 rounded-lg" onclick="revealCaption(2)">Level 2: Add Detail</button>
                        <button class="btn-reveal bg-teal-600 hover:bg-teal-700 text-white font-bold py-2 px-4 rounded-lg" onclick="revealCaption(3)">Level 3: Full Picture</button>
                    </div>
                    <div id="caption-display" class="mt-4">
                        <div id="level-1" class="caption-level card p-4 rounded-lg">
                            <p>"A woman is standing in a kitchen."</p>
                        </div>
                        <div id="level-2" class="caption-level card p-4 rounded-lg">
                            <p>"A smiling woman with a red apron is standing in a modern kitchen, holding a wooden spoon."</p>
                        </div>
                        <div id="level-3" class="caption-level card p-4 rounded-lg">
                            <p>"A smiling woman with a red apron is standing in a modern kitchen, holding a wooden spoon over a steaming pot on the stove. Sunlight is streaming through a window on the left."</p>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- Results Section -->
        <section class="container mx-auto px-6 mb-24">
            <div class="text-center mb-12">
                <h2 class="text-3xl md:text-4xl font-bold text-white">Measuring Success</h2>
                <p class="text-lg text-gray-400 mt-2 max-w-2xl mx-auto">We evaluated our model using standard metrics that compare AI-generated captions to human-written ones.</p>
            </div>
            <div class="card p-8 rounded-xl">
                <h3 class="text-xl font-bold text-white text-center mb-6">ClipCapGAT vs. Baseline</h3>
                <div class="overflow-x-auto">
                    <table class="w-full text-left">
                        <thead>
                            <tr class="border-b border-gray-600">
                                <th class="p-4">Metric</th>
                                <th class="p-4 text-center">Baseline (ClipCap)</th>
                                <th class="p-4 text-center text-purple-400 font-bold">Our Model (ClipCapGAT)</th>
                                <th class="p-4 text-center">Improvement</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr class="border-b border-gray-700">
                                <td class="p-4 font-semibold">BLEU-1</td>
                                <td class="p-4 text-center">35.6</td>
                                <td class="p-4 text-center font-bold text-white">43.7</td>
                                <td class="p-4 text-center text-green-400">+22.7%</td>
                            </tr>
                            <tr class="border-b border-gray-700">
                                <td class="p-4 font-semibold">METEOR</td>
                                <td class="p-4 text-center">7.3</td>
                                <td class="p-4 text-center font-bold text-white">9.5</td>
                                <td class="p-4 text-center text-green-400">+30.1%</td>
                            </tr>
                            <tr class="border-b border-gray-700">
                                <td class="p-4 font-semibold">ROUGE-L</td>
                                <td class="p-4 text-center">27.8</td>
                                <td class="p-4 text-center font-bold text-white">32.0</td>
                                <td class="p-4 text-center text-green-400">+15.1%</td>
                            </tr>
                            <tr>
                                <td class="p-4 font-semibold">CIDEr</td>
                                <td class="p-4 text-center">4.1</td>
                                <td class="p-4 text-center font-bold text-white">6.8</td>
                                <td class="p-4 text-center text-green-400">+65.8%</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
                 <p class="text-xs text-gray-500 mt-4 text-center">Results show significant improvements across all major captioning evaluation metrics, especially CIDEr, which is designed to measure human-like consensus.</p>
            </div>
        </section>

        <!-- Future Directions Section -->
        <section class="container mx-auto px-6">
            <div class="text-center mb-12">
                <h2 class="text-3xl md:text-4xl font-bold text-white">The Vision for a More Accessible World</h2>
                <p class="text-lg text-gray-400 mt-2 max-w-2xl mx-auto">This project is a step toward a future where AI serves as a true visual interpreter.</p>
            </div>
            <div class="grid md:grid-cols-2 gap-8">
                <div class="card p-8 rounded-xl">
                    <h3 class="text-xl font-bold text-white mb-4">Future Work</h3>
                    <ul class="list-disc list-inside text-gray-300 space-y-2">
                        <li>Use sub-graphs to model different priority levels for even more nuanced descriptions.</li>
                        <li>Explore other forms of feature aggregation to capture more complex relationships.</li>
                        <li>Expand the model to understand and describe text within images.</li>
                    </ul>
                </div>
                <div class="card p-8 rounded-xl">
                    <h3 class="text-xl font-bold text-white mb-4">The Goal</h3>
                    <p class="text-gray-300">The work continues, but the vision is clear: to harness the power of AI not just to see the world, but to share its stories with everyone, offering not just access, but understanding.</p>
                </div>
            </div>
        </section>
    </main>

    <!-- Footer -->
    <footer class="bg-gray-900 text-gray-400 text-center p-8 mt-16">
        <div class="container mx-auto">
            <p class="font-bold text-white">Taraneh Ghandi</p>
            <p class="text-sm">Master's Thesis, February 2023</p>
            <p class="text-sm mt-2">Supervisors: Dr. Hamid-Reza Pourreza & Dr. Hamid-Reza Mahyar</p>
            <p class="text-sm">Ferdowsi University of Mashhad | Machine Vision Lab</p>
        </div>
    </footer>

    <script>
        function revealCaption(level) {
            // Hide all levels first
            document.getElementById('level-1').classList.remove('active');
            document.getElementById('level-2').classList.remove('active');
            document.getElementById('level-3').classList.remove('active');

            // Show the selected level
            document.getElementById('level-' + level).classList.add('active');
        }
    </script>

</body>
</html>
